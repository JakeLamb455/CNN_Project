{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64344a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90487c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alex_images_path = \"Alex_Kelly_Pics/Alex\"\n",
    "kelly_images_path = \"Alex_Kelly_Pics/Kelly\"\n",
    "test_images_path = \"Alex_Kelly_Pics/TestSet\"\n",
    "image_labels_path = \"Kelly_and_Alex_Image_Labels - Sheet1.csv\"\n",
    "neither_images_path = \"Neither_pics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef1185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sorted_image_names(path):\n",
    "    return sorted(os.listdir(path), key=lambda x: int(''.join(filter(str.isdigit, x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79187f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alex_image_names = sorted_image_names(alex_images_path)\n",
    "kelly_image_names = sorted_image_names(kelly_images_path)\n",
    "test_image_names = sorted_image_names(test_images_path)\n",
    "\n",
    "image_names = alex_image_names + kelly_image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c2ddd5-0e0c-405b-805d-c21cf82a1c47",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(image_labels_path)\n",
    "le = LabelEncoder().fit(labels[\"Landscape\"])\n",
    "labels[\"Landscape\"] = le.transform(labels[\"Landscape\"])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c9f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels['Photographer'] = labels['image_name'].str.split('-', n = 1).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c061f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(labels[\"Photographer\"])\n",
    "labels[\"Photographer\"] = le.transform(labels[\"Photographer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfdd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533776f9-43aa-481c-b901-b881f4ab2d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_largest_size(folder):\n",
    "    biggest_image = [0, 0]\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(os.path.join(folder, filename))\n",
    "        if img.size[0] > biggest_image[0]: \n",
    "            biggest_image[0] = img.size[0]\n",
    "        if img.size[1] > biggest_image[1]:\n",
    "            biggest_image[1] = img.size[1]\n",
    "    return biggest_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51c0b16-8e5b-4e8f-82a3-dd3cddd6ad1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alex_im_size = get_largest_size(alex_images_path)\n",
    "kelly_im_size = get_largest_size(kelly_images_path)\n",
    "test_im_size = get_largest_size(test_images_path)\n",
    "\n",
    "print(\"Max Image Sizes:\", max(alex_im_size, kelly_im_size, test_im_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5274278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, resize_shape=(700, 440)):\n",
    "    images = []\n",
    "    image_names = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        count += 1\n",
    "        img = Image.open(os.path.join(folder, filename)).convert('RGB')\n",
    "        img = img.resize(resize_shape)\n",
    "        if img is not None:\n",
    "            img_array = np.array(img)\n",
    "            img_array = img_array.flatten()\n",
    "            attr = labels[labels[\"image_name\"] == filename].drop(\"image_name\", axis = 1).to_numpy()\n",
    "            img_array = np.append(img_array, attr)\n",
    "            images.append(img_array)\n",
    "            \n",
    "        if count % int(len(os.listdir(folder)) / 10) == 0:\n",
    "            print(f\"{count / len(os.listdir(folder))*100}% Complete\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d832ff32-f0b1-42a8-90f2-581ea8d620ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "alex_images = load_images_from_folder(alex_images_path)\n",
    "kelly_images = load_images_from_folder(kelly_images_path)\n",
    "test_images = load_images_from_folder(test_images_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d05ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alex_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9fa54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_array = np.array(test_images)\n",
    "del(test_images)\n",
    "test_images = test_images_array[:, 0:924000]\n",
    "test_images = test_images / 255.0\n",
    "test_images = test_images.reshape(test_images.shape[0], 700, 440, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc48c90a-8a7a-437a-a249-03df749a67d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_dataset = np.concatenate([alex_images, kelly_images])\n",
    "del(alex_images, kelly_images) # Free up memory\n",
    "merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f50a2e-40db-4abe-9105-69ea501220dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_attributes = labels.shape[1] - 1\n",
    "\n",
    "attribute_index = list(range(924000, 924000+num_attributes))\n",
    "\n",
    "attributes = [col for col in labels.columns if col != \"image_name\"]\n",
    "\n",
    "attr_dict = dict(zip(attributes, attribute_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00bc4c",
   "metadata": {},
   "source": [
    "# CNN - Sunset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb87899-7a53-4ae4-9599-71f33ed27a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Sunset\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Sunset model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()\n",
    "\n",
    "Sunset_classifications = model.predict(test_images)\n",
    "\n",
    "Sunset_binary_classifications = (Sunset_classifications >= .5).astype(int)\n",
    "\n",
    "Sunset_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddba8bf",
   "metadata": {},
   "source": [
    "# CNN - Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f62b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Flower\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ddae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91fd891",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Flower model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flower_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "Flower_binary_classifications = (Flower_classifications > threshold).astype(int)\n",
    "\n",
    "Flower_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154918ab",
   "metadata": {},
   "source": [
    "# CNN - Animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf587bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Animal\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f643ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Animal model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "Animal_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "Animal_binary_classifications = (Animal_classifications > threshold).astype(int)\n",
    "\n",
    "Animal_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a95cee",
   "metadata": {},
   "source": [
    "# CNN - Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f3891",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Building\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Building model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Building_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "Building_binary_classifications = (Building_classifications > threshold).astype(int)\n",
    "\n",
    "Building_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b054395",
   "metadata": {},
   "source": [
    "# CNN - Mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Building\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c491c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Building model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f09049",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mask_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "Mask_binary_classifications = (Mask_classifications > threshold).astype(int)\n",
    "\n",
    "Mask_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c2107f",
   "metadata": {},
   "source": [
    "# CNN - Gray-Hair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aab4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Gray-Hair\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Gray-hair model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5383fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "gray_binary_classifications = (gray_classifications > threshold).astype(int)\n",
    "\n",
    "gray_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a88b8",
   "metadata": {},
   "source": [
    "# CNN - Fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Fire\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7298ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Fire model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a46cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "fire_binary_classifications = (fire_classifications > threshold).astype(int)\n",
    "\n",
    "fire_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e39d451",
   "metadata": {},
   "source": [
    "# CNN - Food_drink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Food_drink\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30124550",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Food_drink model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e52d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "food_binary_classifications = (food_classifications > threshold).astype(int)\n",
    "\n",
    "food_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af897b84",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cfc88",
   "metadata": {},
   "source": [
    "Load in Dependencies for the Modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04437629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b759e6c",
   "metadata": {},
   "source": [
    "Create variables to hold the file paths for each of the image types. We have one for the Alex images, one for the Kelly images, one for the test images, and one for the neither images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a5a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_images_path = \"Alex_Kelly_Pics/Alex\"\n",
    "kelly_images_path = \"Alex_Kelly_Pics/Kelly\"\n",
    "test_images_path = \"Alex_Kelly_Pics/TestSet\"\n",
    "neither_images_path = \"Neither_pics\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5bfbc",
   "metadata": {},
   "source": [
    "This function below takes a folder of images and then converts the images in the folder to an RGB format. It also takes in the label for each image folder (Alex (0), Kelly (1), and Neither (2)) and appends the labels to the array. The output of this function is the images from a folder in RGB pixel format as well as the labels for the folder of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658d24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, label, resize_shape=(700, 440)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(os.path.join(folder, filename)).convert('RGB')\n",
    "        img = img.resize(resize_shape)\n",
    "        if img is not None:\n",
    "            img_array = np.array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db789730",
   "metadata": {},
   "source": [
    "The code below uses the load_images_from_folder function to create labels and pixelated image values for each of the image folders. The all_images array combines the alex_images, kelly_images, and neither_images arrays. The all_labels array creates an array of all of the 3 labels categorized for the model classification. The all_images array is then divided by 255 so that all of the image values are between 0 and 1 (normalized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab56df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_images, alex_labels = load_images_from_folder(alex_images_path, label=0)\n",
    "kelly_images, kelly_labels = load_images_from_folder(kelly_images_path, label=1)\n",
    "neither_images, neither_labels = load_images_from_folder(neither_images_path, label=2)\n",
    "\n",
    "all_images = np.array(alex_images + kelly_images + neither_images)\n",
    "all_labels = np.array(alex_labels + kelly_labels + neither_labels)\n",
    "del(alex_images, kelly_images, neither_images)\n",
    "\n",
    "all_labels = to_categorical(all_labels, num_classes=3)\n",
    "\n",
    "all_images = all_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee1315",
   "metadata": {},
   "source": [
    "We then created a train test split with the all_images as the X and the all_labels as the y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c17b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec2503",
   "metadata": {},
   "source": [
    "The model below uses a 2d convolution layer with 24 filters. The Max Pool then reduces the spatial dimensions of the input layer. The flatten component flattens the previous layer. The first dense layer uses 256 neurons with reLu activation. The final output layer is a dense layer with 3 outputs using softmax activation. The model uses an adam optimizer and uses the categorical cross entropy loss function. It uses accuracy as the scoring metric. The model is then fit on the training data with a batch size of 32 and 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e472fa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, validation_data = (X_test, y_test), callbacks=LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0), verbose=2)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b85367",
   "metadata": {},
   "source": [
    "The function below (load_images_from_folder_2 takes a folder of images and a resize shape and then returns the images in an array from the folder in RGB pixel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091523f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder_2(folder, resize_shape=(700, 440)):\n",
    "    images = []\n",
    "    image_names = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        count += 1\n",
    "        img = Image.open(os.path.join(folder, filename)).convert('RGB')\n",
    "        img = img.resize(resize_shape)\n",
    "        if img is not None:\n",
    "            img_array = np.array(img)\n",
    "            img_array = img_array.flatten()\n",
    "            images.append(img_array)\n",
    "            \n",
    "        if count % int(len(os.listdir(folder)) / 10) == 0:\n",
    "            print(f\"{count / len(os.listdir(folder))*100}% Complete\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff48042",
   "metadata": {},
   "source": [
    "The cell below uses the load_images_from_folder_2 function to load in the test_images. The test images are then made into an array in line 2. That array is then filtered to select all of the rows and only the first 924000 columns from the array in line 3. In line 4, all of the pixel integers are then converted to a number between 0 and 1 to normalize. The final step was to reshape the test_images to same format as the train images so that they can be used on our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = load_images_from_folder_2(test_images_path)\n",
    "test_images_array = np.array(test_images)\n",
    "test_images = test_images_array[:, 0:924000]\n",
    "test_images = test_images / 255.0\n",
    "test_images = test_images.reshape(test_images.shape[0], 700, 440, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb6ace4",
   "metadata": {},
   "source": [
    "The test_probs variable is a 3 column array that holds the probs that an image is of that class from 0 to 2. This is because the model created above is used on the test images. The test_preds variable then converts these probabilities to either a 0,1, or 2 based on which probability is highest in a given row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9104a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = model.predict(test_images)\n",
    "\n",
    "test_preds = np.argmax(test_probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfb60ad",
   "metadata": {},
   "source": [
    "The 0s, 1s, and 2s are then mapped back to the original names of Alex for 0, Kelly for 1, and Neither for 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: 'Alex',\n",
    "    1: 'Kelly',\n",
    "    2: 'Neither'\n",
    "}\n",
    "\n",
    "test_image_names = [label_mapping[label] for label in test_preds]\n",
    "\n",
    "\n",
    "test_image_names = np.array(test_image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ca408f",
   "metadata": {},
   "source": [
    "A dataframe is then created with the names of the images as a column and then the image classification as another column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_n = [f'test-image-{i+1:02d}' for i in range(len(test_image_names))]\n",
    "\n",
    "test_names_df = pd.DataFrame({\n",
    "    'Test Image Name': image_n,\n",
    "    'Classification': test_image_names\n",
    "})\n",
    "test_names_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
