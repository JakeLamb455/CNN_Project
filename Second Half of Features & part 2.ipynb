{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d64344a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90487c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alex_images_path = \"Alex_Kelly_Pics/Alex\"\n",
    "kelly_images_path = \"Alex_Kelly_Pics/Kelly\"\n",
    "test_images_path = \"Alex_Kelly_Pics/TestSet\"\n",
    "image_labels_path = \"Kelly_and_Alex_Image_Labels - Sheet1.csv\"\n",
    "neither_images_path = \"Neither_pics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47ef1185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sorted_image_names(path):\n",
    "    return sorted(os.listdir(path), key=lambda x: int(''.join(filter(str.isdigit, x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79187f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alex_image_names = sorted_image_names(alex_images_path)\n",
    "kelly_image_names = sorted_image_names(kelly_images_path)\n",
    "test_image_names = sorted_image_names(test_images_path)\n",
    "\n",
    "image_names = alex_image_names + kelly_image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88c2ddd5-0e0c-405b-805d-c21cf82a1c47",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Human</th>\n",
       "      <th>Castle</th>\n",
       "      <th>Indoors</th>\n",
       "      <th>Landscape</th>\n",
       "      <th>Woman</th>\n",
       "      <th>Daytime</th>\n",
       "      <th>Children</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>Flower</th>\n",
       "      <th>Animal</th>\n",
       "      <th>Building</th>\n",
       "      <th>Mask</th>\n",
       "      <th>Gray-Hair</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Food_drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex-Image01.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alex-Image02.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alex-Image03.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alex-Image04.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alex-Image05.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Kelly-Image225.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Kelly-Image226.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>Kelly-Image227.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>Kelly-Image228.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>Kelly-Image229.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_name  Human  Castle  Indoors  Landscape  Woman  Daytime  \\\n",
       "0      Alex-Image01.png      1       0        0          3      0        1   \n",
       "1      Alex-Image02.png      1       0        0          3      0        1   \n",
       "2      Alex-Image03.png      0       0        0          0      0        1   \n",
       "3      Alex-Image04.png      0       0        0          1      0        1   \n",
       "4      Alex-Image05.png      0       0        0          1      0        1   \n",
       "..                  ...    ...     ...      ...        ...    ...      ...   \n",
       "480  Kelly-Image225.png      0       0        0          1      0        1   \n",
       "481  Kelly-Image226.png      0       0        0          1      0        0   \n",
       "482  Kelly-Image227.png      1       0        1          0      0        0   \n",
       "483  Kelly-Image228.png      1       0        0          0      0        1   \n",
       "484  Kelly-Image229.png      1       0        1          0      1        0   \n",
       "\n",
       "     Children  Sunset  Flower  Animal  Building  Mask  Gray-Hair  Fire  \\\n",
       "0           1       0       0       1         0     0          0     0   \n",
       "1           1       0       0       0         1     0          0     0   \n",
       "2           0       0       0       0         1     0          0     0   \n",
       "3           0       0       0       0         0     0          0     0   \n",
       "4           0       0       0       0         0     0          0     0   \n",
       "..        ...     ...     ...     ...       ...   ...        ...   ...   \n",
       "480         0       0       1       1         0     0          0     0   \n",
       "481         0       1       1       0         0     0          0     0   \n",
       "482         0       0       0       1         1     0          0     0   \n",
       "483         0       0       0       0         1     0          0     0   \n",
       "484         0       0       0       0         1     0          0     0   \n",
       "\n",
       "     Food_drink  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "..          ...  \n",
       "480           0  \n",
       "481           0  \n",
       "482           0  \n",
       "483           0  \n",
       "484           0  \n",
       "\n",
       "[485 rows x 16 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(image_labels_path)\n",
    "le = LabelEncoder().fit(labels[\"Landscape\"])\n",
    "labels[\"Landscape\"] = le.transform(labels[\"Landscape\"])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "925c9f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels['Photographer'] = labels['image_name'].str.split('-', n = 1).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c061f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(labels[\"Photographer\"])\n",
    "labels[\"Photographer\"] = le.transform(labels[\"Photographer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "533776f9-43aa-481c-b901-b881f4ab2d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_largest_size(folder):\n",
    "    biggest_image = [0, 0]\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(os.path.join(folder, filename))\n",
    "        if img.size[0] > biggest_image[0]: \n",
    "            biggest_image[0] = img.size[0]\n",
    "        if img.size[1] > biggest_image[1]:\n",
    "            biggest_image[1] = img.size[1]\n",
    "    return biggest_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d51c0b16-8e5b-4e8f-82a3-dd3cddd6ad1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Image Sizes: [667, 400]\n"
     ]
    }
   ],
   "source": [
    "alex_im_size = get_largest_size(alex_images_path)\n",
    "kelly_im_size = get_largest_size(kelly_images_path)\n",
    "test_im_size = get_largest_size(test_images_path)\n",
    "\n",
    "print(\"Max Image Sizes:\", max(alex_im_size, kelly_im_size, test_im_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5274278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, resize_shape=(700, 440)):\n",
    "    images = []\n",
    "    image_names = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        count += 1\n",
    "        img = Image.open(os.path.join(folder, filename)).convert('RGB')\n",
    "        img = img.resize(resize_shape)\n",
    "        if img is not None:\n",
    "            img_array = np.array(img)\n",
    "            img_array = img_array.flatten()\n",
    "            attr = labels[labels[\"image_name\"] == filename].drop(\"image_name\", axis = 1).to_numpy()\n",
    "            img_array = np.append(img_array, attr)\n",
    "            images.append(img_array)\n",
    "            \n",
    "        if count % int(len(os.listdir(folder)) / 10) == 0:\n",
    "            print(f\"{count / len(os.listdir(folder))*100}% Complete\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d832ff32-f0b1-42a8-90f2-581ea8d620ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.765625% Complete\n",
      "19.53125% Complete\n",
      "29.296875% Complete\n",
      "39.0625% Complete\n",
      "48.828125% Complete\n",
      "58.59375% Complete\n",
      "68.359375% Complete\n",
      "78.125% Complete\n",
      "87.890625% Complete\n",
      "97.65625% Complete\n",
      "9.606986899563319% Complete\n",
      "19.213973799126638% Complete\n",
      "28.82096069868996% Complete\n",
      "38.427947598253276% Complete\n",
      "48.03493449781659% Complete\n",
      "57.64192139737992% Complete\n",
      "67.24890829694323% Complete\n",
      "76.85589519650655% Complete\n",
      "86.46288209606988% Complete\n",
      "96.06986899563319% Complete\n",
      "10.0% Complete\n",
      "20.0% Complete\n",
      "30.0% Complete\n",
      "40.0% Complete\n",
      "50.0% Complete\n",
      "60.0% Complete\n",
      "70.0% Complete\n",
      "80.0% Complete\n",
      "90.0% Complete\n",
      "100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "alex_images = load_images_from_folder(alex_images_path)\n",
    "kelly_images = load_images_from_folder(kelly_images_path)\n",
    "test_images = load_images_from_folder(test_images_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39d05ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924016"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alex_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd9fa54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_array = np.array(test_images)\n",
    "del(test_images)\n",
    "test_images = test_images_array[:, 0:924000]\n",
    "test_images = test_images / 255.0\n",
    "test_images = test_images.reshape(test_images.shape[0], 700, 440, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc48c90a-8a7a-437a-a249-03df749a67d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[153, 138, 137, ...,   0,   0,   0],\n",
       "       [215, 206, 197, ...,   0,   0,   0],\n",
       "       [103, 113, 121, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 82,  92,  78, ...,   0,   0,   1],\n",
       "       [  5,   7,   6, ...,   0,   0,   1],\n",
       "       [127, 124, 106, ...,   0,   0,   1]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset = np.concatenate([alex_images, kelly_images])\n",
    "del(alex_images, kelly_images) # Free up memory\n",
    "merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41f50a2e-40db-4abe-9105-69ea501220dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_attributes = labels.shape[1] - 1\n",
    "\n",
    "attribute_index = list(range(924000, 924000+num_attributes))\n",
    "\n",
    "attributes = [col for col in labels.columns if col != \"image_name\"]\n",
    "\n",
    "attr_dict = dict(zip(attributes, attribute_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00bc4c",
   "metadata": {},
   "source": [
    "# CNN - Sunset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc04c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Sunset\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Sunset model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sunset_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "Sunset_binary_classifications = (Sunset_classifications > threshold).astype(int)\n",
    "\n",
    "Sunset_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddba8bf",
   "metadata": {},
   "source": [
    "# CNN - Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f62b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Flower\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ddae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91fd891",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Flower model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flower_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "Flower_binary_classifications = (Flower_classifications > threshold).astype(int)\n",
    "\n",
    "Flower_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154918ab",
   "metadata": {},
   "source": [
    "# CNN - Animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf587bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Animal\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f643ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Animal model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "Animal_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "Animal_binary_classifications = (Animal_classifications > threshold).astype(int)\n",
    "\n",
    "Animal_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a95cee",
   "metadata": {},
   "source": [
    "# CNN - Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f3891",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Building\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Building model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Building_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "Building_binary_classifications = (Building_classifications > threshold).astype(int)\n",
    "\n",
    "Building_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b054395",
   "metadata": {},
   "source": [
    "# CNN - Mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Building\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c491c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Building model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f09049",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mask_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "Mask_binary_classifications = (Mask_classifications > threshold).astype(int)\n",
    "\n",
    "Mask_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c2107f",
   "metadata": {},
   "source": [
    "# CNN - Gray-Hair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aab4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Gray-Hair\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Gray-hair model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5383fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "gray_binary_classifications = (gray_classifications > threshold).astype(int)\n",
    "\n",
    "gray_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a88b8",
   "metadata": {},
   "source": [
    "# CNN - Fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Fire\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7298ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Fire model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a46cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "fire_binary_classifications = (fire_classifications > threshold).astype(int)\n",
    "\n",
    "fire_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e39d451",
   "metadata": {},
   "source": [
    "# CNN - Food_drink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_dataset[:, 0:924000]\n",
    "X = X / 255.0\n",
    "y = merged_dataset[:, attr_dict[\"Food_drink\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train = X_train.reshape(X_train.shape[0],700,440,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],700,440,3)\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)\n",
    "styles=[':','-.','--','-',':','-.','--','-',':','-.','--','-']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 20, \n",
    "validation_data = (X_test, y_test), callbacks=[annealer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30124550",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Food_drink model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.60,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e52d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_classifications = model.predict(test_images)\n",
    "\n",
    "threshold = .5\n",
    "food_binary_classifications = (food_classifications > threshold).astype(int)\n",
    "\n",
    "food_binary_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af897b84",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04437629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a5a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_images_path = \"Alex_Kelly_Pics/Alex\"\n",
    "kelly_images_path = \"Alex_Kelly_Pics/Kelly\"\n",
    "test_images_path = \"Alex_Kelly_Pics/TestSet\"\n",
    "image_labels_path = \"Kelly_and_Alex_Image_Labels - Sheet1.csv\"\n",
    "neither_images_path = \"Neither_pics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f1b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "658d24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "def load_images_from_folder(folder, label, resize_shape=(700, 440)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(os.path.join(folder, filename)).convert('RGB')\n",
    "        img = img.resize(resize_shape)\n",
    "        if img is not None:\n",
    "            img_array = np.array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "alex_images, alex_labels = load_images_from_folder(alex_images_path, label=0)\n",
    "kelly_images, kelly_labels = load_images_from_folder(kelly_images_path, label=1)\n",
    "neither_images, neither_labels = load_images_from_folder(neither_images_path, label=2)\n",
    "\n",
    "all_images = np.array(alex_images + kelly_images + neither_images)\n",
    "all_labels = np.array(alex_labels + kelly_labels + neither_labels)\n",
    "del(alex_images, kelly_images, neither_images)\n",
    "\n",
    "all_labels = to_categorical(all_labels, num_classes=3)\n",
    "\n",
    "all_images = all_images / 255.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86c17b35",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.78 GiB for an array with shape (549, 440, 700, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(all_images, all_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda33\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda33\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2640\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2636\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2638\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m-> 2640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2641\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2642\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2643\u001b[0m     )\n\u001b[0;32m   2644\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda33\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2642\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2636\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2638\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2641\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2642\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2643\u001b[0m     )\n\u001b[0;32m   2644\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda33\\Lib\\site-packages\\sklearn\\utils\\__init__.py:355\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32m~\\anaconda33\\Lib\\site-packages\\sklearn\\utils\\__init__.py:184\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    183\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array[key] \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.78 GiB for an array with shape (549, 440, 700, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e472fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "        input_shape=(700,440,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 1, validation_data = (X_test, y_test), callbacks=LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0), verbose=2)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9104a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = model.predict(test_images)\n",
    "\n",
    "test_preds = np.argmax(test_probs, axis=1)\n",
    "\n",
    "test_image_labels = np.argmax(test_preds, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
